{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入下方要使用的所有包\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x.shape  # 访问张量沿每个轴的长度的形状\n",
    "# output ： torch.size([12])\n",
    "x.numel() # shape中所有元素的乘积\n",
    "# output ： 12\n",
    "x_change = x.reshape(3,4) # 改变张量的形状而不改变元素数量和元素值\n",
    "x_change.shape\n",
    "# output ： torch.Size([3, 4])\n",
    "x_change.numel()\n",
    "# output ： 12\n",
    "# concatenate 连结\n",
    "X = torch.arange(12,dtype=torch.float32).reshape(3,4)\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "# dim 0->行拼接；1->列拼接\n",
    "torch.cat((X,Y), dim=0), torch.cat((X,Y),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "广播机制：\n",
    "1、通过适当复制元素来扩展一个或两个数组，以便转换后，两张张量具有相同的形状\n",
    "2、对生成的数组执行按元素操作\n",
    "'''\n",
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "# 这个常来说a和b是无法相加的，因为两者形状不同\n",
    "# 但是通过广播机制将两个矩阵广播为一个更大的(3×2)矩阵中\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对象之间的转换\n",
    "\n",
    "# 1、NumPy张量和torch.tensor之间的转换\n",
    "tensor_to_numpy = X.numpy()  # \n",
    "numpy_to_tensor = torch.tensor(tensor_to_numpy)\n",
    "type(tensor_to_numpy),type(numpy_to_tensor)  \n",
    "#(numpy.ndarray, torch.Tensor)\n",
    "\n",
    "# 2、torch.tensor张量转换为python标量\n",
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)\n",
    "# (tensor([3.5000]), 3.5, 3.5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.9387,  1.3575,  1.2813, -1.1938,  1.2134],\n",
       "          [ 0.9903,  0.2554, -0.3218, -1.1311,  0.0639],\n",
       "          [-1.8448,  1.8138, -1.2115, -1.4867, -0.8529],\n",
       "          [-1.8742, -0.2416,  1.1394, -0.0515,  0.6300]],\n",
       " \n",
       "         [[ 0.0535,  1.2370, -0.5079, -0.1438,  0.7099],\n",
       "          [ 0.3023,  1.0615,  0.7231,  2.0954,  1.2098],\n",
       "          [ 0.4697, -1.9280, -2.0332,  1.4453,  0.3711],\n",
       "          [-0.0384,  1.7899, -0.1977,  0.1268,  0.4820]],\n",
       " \n",
       "         [[-0.9686,  0.1897, -1.3356,  0.7590, -1.2000],\n",
       "          [ 1.1444,  0.8568,  0.3709,  0.0058, -2.5356],\n",
       "          [ 1.0141,  0.6353, -0.7941,  0.6439,  0.3138],\n",
       "          [ 0.8281,  0.7327,  1.2315,  1.0969, -1.3624]]]),\n",
       " tensor([[[ 0.6881, -0.1953,  0.1263,  0.9729,  0.3475]]]),\n",
       " tensor([[[ 1.6268,  1.1622,  1.4075, -0.2210,  1.5609],\n",
       "          [ 1.6784,  0.0601, -0.1955, -0.1582,  0.4114],\n",
       "          [-1.1566,  1.6185, -1.0852, -0.5138, -0.5054],\n",
       "          [-1.1861, -0.4368,  1.2657,  0.9214,  0.9775]],\n",
       " \n",
       "         [[ 0.7416,  1.0417, -0.3817,  0.8291,  1.0574],\n",
       "          [ 0.9904,  0.8663,  0.8493,  3.0682,  1.5573],\n",
       "          [ 1.1578, -2.1232, -1.9069,  2.4181,  0.7187],\n",
       "          [ 0.6497,  1.5946, -0.0714,  1.0997,  0.8295]],\n",
       " \n",
       "         [[-0.2805, -0.0056, -1.2093,  1.7319, -0.8525],\n",
       "          [ 1.8325,  0.6616,  0.4972,  0.9787, -2.1881],\n",
       "          [ 1.7023,  0.4401, -0.6678,  1.6167,  0.6613],\n",
       "          [ 1.5162,  0.5375,  1.3577,  2.0698, -1.0149]]]),\n",
       " torch.Size([3, 4, 5]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "X,Y,X<Y,X>Y\n",
    "# 结果相当于X和Y两个矩阵中的元素一一比较然后得到的矩阵\n",
    "'''相当于对b进行了两次复制：\n",
    " 第一次 1×5 形状的张量复制了4次，变成了 4×5\n",
    " 第二次 1×4×5 形状的张量复制了3次，变成了3×4×5\n",
    "'''\n",
    "a = torch.randn(3,4,5)\n",
    "b = torch.randn(1,1,5)\n",
    "a,b\n",
    "c = a+b\n",
    "a,b,c,c.shape\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studytest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
